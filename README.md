# Cross-situational learning in computational models of visually grounded speech (VGS_XSL)

Python and MATLAB scripts for the experiments reported in manuscript titled "Can phones, syllables, and words emerge as side-products of cross-situational audiovisual learning? --- A computational investigation" by Khazar Khorrami and Okko Räsänen. 


Analysis scripts of hidden layer activations were written mostly in MATLAB, and can be found under `selectivity_analyses/`


Pre-print: add here. 

Models and model activation data are available for download at Zenodo: link added here once Zenodo upload quota request has been approved.

